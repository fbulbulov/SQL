{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76924c0e",
   "metadata": {},
   "source": [
    "## Kaggle SQL Course 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af380f0",
   "metadata": {},
   "source": [
    "**SQL and BigQuery**\n",
    "\n",
    "Introduction\n",
    "\n",
    "Structured Query Language, or SQL, is the programming language used with databases, and it is an important skill for any data scientist. In this course, you'll build your SQL skills using BigQuery, a web service that lets you apply SQL to huge datasets.\n",
    "\n",
    "In this lesson, you'll learn the basics of accessing and examining BigQuery datasets. After you have a handle on these basics, we'll come back to build your SQL skills.\n",
    "\n",
    "To use BigQuery, we'll import the Python package below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa772ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T17:38:23.720533Z",
     "start_time": "2021-07-29T17:38:23.715534Z"
    }
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3816df13",
   "metadata": {},
   "source": [
    "The first step in the workflow is to create a `Client` object. As you'll soon see, this Client object will play a central role in retrieving information from BigQuery datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddaa95",
   "metadata": {},
   "source": [
    "We'll work with a dataset of posts on Hacker News, a website focusing on computer science and cybersecurity news.\n",
    "\n",
    "In BigQuery, each dataset is contained in a corresponding project. In this case, our hacker_news dataset is contained in the `bigquery-public-data` project. To access the dataset,\n",
    "\n",
    "- We begin by constructing a reference to the dataset with the dataset() method.\n",
    "- Next, we use the `get_dataset()` method, along with the reference we just constructed, to fetch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b36f73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T18:09:24.686772Z",
     "start_time": "2021-07-29T18:09:24.641655Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b64de968dc2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Construct a reference to the \"hacker_news\" dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hacker_news\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bigquery-public-data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f187674c",
   "metadata": {},
   "source": [
    "Every dataset is just a collection of tables. You can think of a dataset as a spreadsheet file containing multiple tables, all composed of rows and columns.\n",
    "\n",
    "We use the `list_tables()` method to list the tables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed123df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fea547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34064e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eca51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ba1ef4b",
   "metadata": {},
   "source": [
    "**Farrukh Bulbulov**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
