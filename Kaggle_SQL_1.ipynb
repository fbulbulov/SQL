{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d702f4",
   "metadata": {},
   "source": [
    "## Kaggle SQL Course 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9e66d",
   "metadata": {},
   "source": [
    "**SQL and BigQuery**\n",
    "\n",
    "Introduction\n",
    "\n",
    "Structured Query Language, or SQL, is the programming language used with databases, and it is an important skill for any data scientist. In this course, you'll build your SQL skills using BigQuery, a web service that lets you apply SQL to huge datasets.\n",
    "\n",
    "In this lesson, you'll learn the basics of accessing and examining BigQuery datasets. After you have a handle on these basics, we'll come back to build your SQL skills.\n",
    "\n",
    "To use BigQuery, we'll import the Python package below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4aa8c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T17:38:23.720533Z",
     "start_time": "2021-07-29T17:38:23.715534Z"
    }
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89a78b",
   "metadata": {},
   "source": [
    "The first step in the workflow is to create a `Client` object. As you'll soon see, this Client object will play a central role in retrieving information from BigQuery datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eba3bf",
   "metadata": {},
   "source": [
    "We'll work with a dataset of posts on Hacker News, a website focusing on computer science and cybersecurity news.\n",
    "\n",
    "In BigQuery, each dataset is contained in a corresponding project. In this case, our hacker_news dataset is contained in the `bigquery-public-data` project. To access the dataset,\n",
    "\n",
    "- We begin by constructing a reference to the dataset with the dataset() method.\n",
    "- Next, we use the `get_dataset()` method, along with the reference we just constructed, to fetch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb8ba0da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T18:09:24.686772Z",
     "start_time": "2021-07-29T18:09:24.641655Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b64de968dc2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Construct a reference to the \"hacker_news\" dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hacker_news\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bigquery-public-data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2e329",
   "metadata": {},
   "source": [
    "Every dataset is just a collection of tables. You can think of a dataset as a spreadsheet file containing multiple tables, all composed of rows and columns.\n",
    "\n",
    "We use the `list_tables()` method to list the tables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2a41e",
   "metadata": {},
   "source": [
    "Similar to how we fetched a dataset, we can fetch a table. In the code cell below, we fetch the `full` table in the `hacker_news` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69797d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"full\" table\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5f1bd",
   "metadata": {},
   "source": [
    "**Table schema**\n",
    "\n",
    "The structure of a table is called its schema. We need to understand a table's schema to effectively pull out the data we want.\n",
    "\n",
    "In this example, we'll investigate the full table that we fetched above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5228b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d937a8",
   "metadata": {},
   "source": [
    "**Ex.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3514cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"chicago_crime\" dataset\n",
    "dataset_ref = client.dataset(\"chicago_crime\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6315979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the tables in the \"chicago_crime\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print number of tables in the dataset\n",
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb147f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"crime\" table\n",
    "table_ref = dataset_ref.table(\"crime\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Print information on all the columns in the \"crime\" table in the \"chicago_crime\" dataset\n",
    "print(table.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3673163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a crime map\n",
    "client.list_rows(table, max_results=5).to_dataframe()\n",
    "fields_for_plotting = ['latitude', 'longitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95394f",
   "metadata": {},
   "source": [
    "**Select, From & Where**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106d856",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "Now that you know how to access and examine a dataset, you're ready to write your first SQL query! As you'll soon see, SQL queries will help you sort through a massive dataset, to retrieve only the information that you need.\n",
    "\n",
    "We'll begin by using the keywords SELECT, FROM, and WHERE to get data from specific columns based on conditions you specify.\n",
    "\n",
    "For clarity, we'll work with a small imaginary dataset pet_records which contains just one table, called pets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6037c7",
   "metadata": {},
   "source": [
    "SELECT ... FROM\n",
    "The most basic SQL query selects a single column from a single table. To do this,\n",
    "\n",
    "specify the column you want after the word SELECT, and then\n",
    "specify the table after the word FROM.\n",
    "For instance, to select the Name column \n",
    "\n",
    "Note that when writing an SQL query, the argument we pass to FROM is not in single or double quotation marks (' or \"). It is in backticks (`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f7ffe",
   "metadata": {},
   "source": [
    "WHERE ...\n",
    "BigQuery datasets are large, so you'll usually want to return only the rows meeting specific conditions. You can do this using the WHERE clause.\n",
    "\n",
    "The query below returns the entries from the Name column that are in rows where the Animal column has the text 'Cat'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1a869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c53bb3a",
   "metadata": {},
   "source": [
    "**Farrukh Bulbulov**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
